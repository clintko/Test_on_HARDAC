{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ./ex_toy02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ./ex_toy02/normal_mixture.stan << EOF\n",
    "data {\n",
    "    int<lower=1> N; // number of data points; lower = 1 means to constrain N > 0\n",
    "    real X[N];      // X[i] = gene expression for individual i\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real <lower=0, upper=1> r; // mixture proportion\n",
    "    real mu;                   // mu = mean of individuals w/ decreased expression\n",
    "    real<lower=0.001> sigma;   // sigma = variance of expression > 0\n",
    "}\n",
    "\n",
    "model {\n",
    "    r ~ beta(2,2);\n",
    "    mu ~ normal(0,10);\n",
    "    sigma ~ inv_gamma(1,1);\n",
    "    for (i in 1:N) \n",
    "        target += log_sum_exp(\n",
    "            log(r)   + normal_lpdf(X[i] | mu, sigma),\n",
    "            log(1-r) + normal_lpdf(X[i] |  0, sigma));\n",
    "}\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/fs1/data/reddylab/Kuei/learn/learn_stan\n",
      "make: Entering directory `/gpfs/fs1/data/reddylab/Kuei/exe/cmdstan'\n",
      "\n",
      "--- Translating Stan model to C++ code ---\n",
      "bin/stanc  --o=/gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture.hpp /gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture.stan\n",
      "\n",
      "--- Compiling, linking C++ code ---\n",
      "g++ -std=c++1y -pthread -D_REENTRANT -Wno-sign-compare -Wno-ignored-attributes      -I stan/lib/stan_math/lib/tbb_2020.3/include   -O3 -I src -I stan/src -I lib/rapidjson_1.1.0/ -I lib/CLI11-1.9.1/ -I stan/lib/stan_math/ -I stan/lib/stan_math/lib/eigen_3.3.9 -I stan/lib/stan_math/lib/boost_1.75.0 -I stan/lib/stan_math/lib/sundials_5.7.0/include    -DBOOST_DISABLE_ASSERTS         -c -Wno-ignored-attributes   -x c++ -o /gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture.o /gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture.hpp\n",
      "g++ -std=c++1y -pthread -D_REENTRANT -Wno-sign-compare -Wno-ignored-attributes      -I stan/lib/stan_math/lib/tbb_2020.3/include   -O3 -I src -I stan/src -I lib/rapidjson_1.1.0/ -I lib/CLI11-1.9.1/ -I stan/lib/stan_math/ -I stan/lib/stan_math/lib/eigen_3.3.9 -I stan/lib/stan_math/lib/boost_1.75.0 -I stan/lib/stan_math/lib/sundials_5.7.0/include    -DBOOST_DISABLE_ASSERTS               -Wl,-L,\"/nfs/software/helmod/apps/Core/tbb/4.4-fasrc02/lib\" -Wl,-rpath,\"/nfs/software/helmod/apps/Core/tbb/4.4-fasrc02/lib\" -ltbb    /gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture.o src/cmdstan/main.o        -Wl,-L,\"/nfs/software/helmod/apps/Core/tbb/4.4-fasrc02/lib\" -Wl,-rpath,\"/nfs/software/helmod/apps/Core/tbb/4.4-fasrc02/lib\" -ltbb stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_nvecserial.a stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_cvodes.a stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_idas.a stan/lib/stan_math/lib/sundials_5.7.0/lib/libsundials_kinsol.a   -o /gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture\n",
      "rm -f /gpfs/fs1/data/reddylab/Kuei/learn/learn_stan/ex_toy02/normal_mixture.o\n",
      "make: Leaving directory `/gpfs/fs1/data/reddylab/Kuei/exe/cmdstan'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "### load modules\n",
    "module load gcc\n",
    "module load tbb\n",
    "\n",
    "### set directory\n",
    "STAN_PATH=/data/reddylab/Kuei/exe/cmdstan\n",
    "FD_WRK=$(pwd)\n",
    "echo $FD_WRK\n",
    "\n",
    "### compile model\n",
    "make -C $STAN_PATH ${FD_WRK}/ex_toy02/normal_mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "Mean: 0.0\n",
      "SD:   0.36\n",
      "neg\n",
      "Mean: -0.99\n",
      "SD:   0.32\n"
     ]
    }
   ],
   "source": [
    "### simulation\n",
    "np.random.seed(123)\n",
    "pos = np.random.normal(loc= 0, scale=0.3, size=50)\n",
    "neg = np.random.normal(loc=-1, scale=0.3, size=50)\n",
    "\n",
    "print(\"pos\")\n",
    "print(\"Mean:\", np.around(pos.mean(), 2))\n",
    "print(\"SD:  \", np.around(pos.std(),  2))\n",
    "\n",
    "print(\"neg\")\n",
    "print(\"Mean:\", np.around(neg.mean(), 2))\n",
    "print(\"SD:  \", np.around(neg.std(),  2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate data file\n",
    "dct = dict()\n",
    "dct[\"N\"] = 100\n",
    "dct[\"X\"] = pos.tolist() + neg.tolist()\n",
    "\n",
    "### store the data\n",
    "fpath = \"./ex_toy02/inputs.json\"\n",
    "with open(fpath, \"w\") as file:\n",
    "    json.dump(dct, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method = sample (Default)\n",
      "  sample\n",
      "    num_samples = 1000 (Default)\n",
      "    num_warmup = 50\n",
      "    save_warmup = 0 (Default)\n",
      "    thin = 1 (Default)\n",
      "    adapt\n",
      "      engaged = 1 (Default)\n",
      "      gamma = 0.050000000000000003 (Default)\n",
      "      delta = 0.80000000000000004 (Default)\n",
      "      kappa = 0.75 (Default)\n",
      "      t0 = 10 (Default)\n",
      "      init_buffer = 75 (Default)\n",
      "      term_buffer = 50 (Default)\n",
      "      window = 25 (Default)\n",
      "    algorithm = hmc (Default)\n",
      "      hmc\n",
      "        engine = nuts (Default)\n",
      "          nuts\n",
      "            max_depth = 10 (Default)\n",
      "        metric = diag_e (Default)\n",
      "        metric_file =  (Default)\n",
      "        stepsize = 1 (Default)\n",
      "        stepsize_jitter = 0 (Default)\n",
      "id = 0 (Default)\n",
      "data\n",
      "  file = ./ex_toy02/inputs.json\n",
      "init = 2 (Default)\n",
      "random\n",
      "  seed = 3001794802 (Default)\n",
      "output\n",
      "  file = ./ex_toy02/output.csv\n",
      "  diagnostic_file =  (Default)\n",
      "  refresh = 100 (Default)\n",
      "  sig_figs = -1 (Default)\n",
      "  profile_file = profile.csv (Default)\n",
      "\n",
      "\n",
      "Gradient evaluation took 0.000233 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 2.33 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "WARNING: There aren't enough warmup iterations to fit the\n",
      "         three stages of adaptation as currently configured.\n",
      "         Reducing each adaptation stage to 15%/75%/10% of\n",
      "         the given number of warmup iterations:\n",
      "           init_buffer = 7\n",
      "           adapt_window = 38\n",
      "           term_buffer = 5\n",
      "\n",
      "Iteration:    1 / 1050 [  0%]  (Warmup)\n",
      "Iteration:   51 / 1050 [  4%]  (Sampling)\n",
      "Iteration:  150 / 1050 [ 14%]  (Sampling)\n",
      "Iteration:  250 / 1050 [ 23%]  (Sampling)\n",
      "Iteration:  350 / 1050 [ 33%]  (Sampling)\n",
      "Iteration:  450 / 1050 [ 42%]  (Sampling)\n",
      "Iteration:  550 / 1050 [ 52%]  (Sampling)\n",
      "Iteration:  650 / 1050 [ 61%]  (Sampling)\n",
      "Iteration:  750 / 1050 [ 71%]  (Sampling)\n",
      "Iteration:  850 / 1050 [ 80%]  (Sampling)\n",
      "Iteration:  950 / 1050 [ 90%]  (Sampling)\n",
      "Iteration: 1050 / 1050 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 0.038 seconds (Warm-up)\n",
      "               0.461 seconds (Sampling)\n",
      "               0.499 seconds (Total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "module load gcc\n",
    "./ex_toy02/normal_mixture sample \\\n",
    "    thin=1 num_samples=1000 num_warmup=50 \\\n",
    "    data file=./ex_toy02/inputs.json \\\n",
    "    output file=./ex_toy02/output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: normal_mixture_model\n",
      "1 chains: each with iter=(1000); warmup=(0); thin=(1); 1000 iterations saved.\n",
      "\n",
      "Warmup took 0.038 seconds\n",
      "Sampling took 0.46 seconds\n",
      "\n",
      "                 Mean     MCSE   StdDev     5%    50%    95%    N_Eff  N_Eff/s    R_hat\n",
      "\n",
      "lp__              -93  8.6e-02      1.4    -96    -92    -91      278      603      1.0\n",
      "accept_stat__    0.91  3.2e-03  1.1e-01   0.67   0.95    1.0  1.2e+03  2.7e+03  1.0e+00\n",
      "stepsize__      0.062      nan  2.7e-16  0.062  0.062  0.062      nan      nan      nan\n",
      "treedepth__       2.6  2.4e-02  6.8e-01    2.0    3.0    4.0  8.0e+02  1.7e+03  1.0e+00\n",
      "n_leapfrog__      8.0  1.5e-01  4.7e+00    3.0    7.0     15  9.8e+02  2.1e+03  1.0e+00\n",
      "divergent__      0.00      nan  0.0e+00   0.00   0.00   0.00      nan      nan      nan\n",
      "energy__           94  1.2e-01  2.0e+00     92     94     98  3.0e+02  6.4e+02  1.0e+00\n",
      "\n",
      "r                0.53  5.4e-03    0.077   0.41   0.53   0.65      202      437      1.0\n",
      "mu              -0.93  5.2e-03    0.095   -1.1  -0.94  -0.75      328      712     1.00\n",
      "sigma            0.39  3.0e-03    0.054   0.32   0.38   0.50      322      699     1.00\n",
      "\n",
      "Samples were drawn using hmc with nuts.\n",
      "For each parameter, N_Eff is a crude measure of effective sample size,\n",
      "and R_hat is the potential scale reduction factor on split chains (at \n",
      "convergence, R_hat=1).\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "module load gcc\n",
    "STAN_PATH=/data/reddylab/Kuei/exe/cmdstan\n",
    "$STAN_PATH/bin/stansummary ./ex_toy02/output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
